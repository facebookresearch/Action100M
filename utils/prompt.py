import json

RESPONSE_STRUCTURE=json.dumps({
    "type": "object",
    "properties": {
        "summary": {
            "type": "object", 
            "properties": {
                "brief": {"type": "string", "description": "Single sentence video caption."},
                "detailed": {"type": "string","description": "Detailed, comprehensive description."},
                },
            },
        "action":  {
            "type": "object", 
            "properties": {
                "brief": {"type": "string","description": "A single verb phrase (no -ing forms) brifly summarizing the overall action content."},
                "detailed": {"type": "string","description": "A single imperitive sentence describing how the action is performed with more details."},
                "actor": {"type": "string", "description": "Single sentece or an imformative noun phrase describing who is performing the action."},
                },
            },
        },
    "required": ["summary", "action"]
    }, 
    ensure_ascii=False)



TASK_TEMPLATE = """The task is to extract structured information from a video segment. The segment spans from {start_time} to {end_time} seconds, within a larger video that runs from {global_start_time} to {global_end_time} seconds. You will be provided with hierarchical captions generated by models operating on local windows or frames. These captions may contain errors or hallucinations. Your goal is to carefully aggregate the information from the captions to produce an accurate, coherent description of this specific segment.

Guidelines and requirements:

- Focus on what is visually observable, emphasizing both 1) physical motion, procedural actions, and 2) appearance information, background or text if possible.
- The timestamps in video metadata and markdown titles are generally reliable, but those inside the captions are not.  
- Use global captions and video metadata only for disambiguation. Do not add visually unobservable information (e.g., content of speech, names that cannot be inferred from the local video segment) to the results.
- The result covers the current segment ({start_time} to {end_time}) only, not the entire video.
- Ignore captions from very short edges at the start or end of the segment if they are semantically discontinuous (e.g., due to scene transitions). Focus on the main central portion of the segment.
- Due to the limited perception of local models and possible hallucinations, there may be inconsistencies among captions. 
- Be cautious and conservative, and rely on the majority consensus.  
- Think hard. Perform in-depth reasoning to discuss the provided captions and global context, then output a JSON containing final results in plain English text.
- For all fields, use coherent full sentences with proper capitalization and punctuation. Use concise noun phrases without unnecessary qualifiers or parenthetical clarifications.


### Task 1. Summarization

Generate both a short informative caption and a comprehensive, dense summary of the video segment. Describe events in chronological order, but do not mention any exact timestamps in the summary. Include 

### Task 2. Action Identification

Identify the main actor and the physical action performed in the current segment. Provide both a brief description that represents the overall action step, and a detailed description that contains sufficient procedural detail. Use “N/A” (without further explaination) if there are no visible actors or physical actions (e.g., static).

# Response Formats
## output
{response_strucutre}
"""

INPUT_TEMPLATE = """
# Video metadata

```yaml
{video_metadata}
```

# Global video context
{global_tree}

# Current segment to be processed

{current_tree}
"""

REFINE_INSTRUCTION = """# Your Task

Now, carefully analyze, verify, and revise the previous draft so that it is fully accurate, faithful to the provided content, and strictly adheres to all stated guidelines and requirements.
"""
